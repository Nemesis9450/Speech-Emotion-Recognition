## Speech-Emotion-Recognition
Speech emotion recognition using both Traditional machine learning models as well Deep learning model using CNN and LSTM and predicting over 7 emotions (Angry, Sad ,Happy , Neutral ,Fear, Disgust and Surprise) .

#Dataset
I have used total of 5 datasets these are as:
1.RAVDESS : Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS)
 dataset is a comprehensive multimodal resource for emotional expression, con
taining audio, video, and song modalities. For this study, we utilized the audio
only portion, which consists of approx 7356 speech files (16-bit, 48kHz .wav)
 from 24 professional actors (12 female, 12 male). 

2.TESS:The Toronto Emotional Speech Set (TESS) is a unique dataset developed at
 the University of Toronto, focusing exclusively on female emotional speech. It
 comprises 2,800 utterances from two female actresses, aged 26 and 64 years,
 portraying seven emotional states: anger, disgust, fear, happiness, pleasant
 surprise, sadness, and neutral.

3.EmoDB: The Berlin Emotional Speech Database (Emo-DB) is a widely recognized and
 freely available German emotional speech database, created by the Institute of
 Communication Science at the Technical University of Berlin. It contains a
 total of 535 utterances spoken by 10 professional actors (5 male and 5 female),
 ensuring a balanced representation of gender.

4. ESD: TheEmotional Speech Dataset (ESD) is a specialized dataset designed for voice
 conversion research, with a particular focus on emotional speech. It consists of
 11
35,000 files, comprising 350 parallel utterances spoken by 20 speakers: 10 native
 English and 10 native Chinese speakers. The dataset covers five emotion categories: neutral, happy, angry, sad, and
 surprise, providing a diverse yet focused set of emotions for analysis. More
 than 29 hours of speech data were meticulously recorded in a controlled acoustic
 environment, ensuring high-quality audio and minimizing external noise factors.

5.CUSTOM:Acustomdataset is To address the under-representation of the emotions disgust
 and fear in existing datasets, a custom dataset was curated, comprising approx
imately 6,000 audio files explicitly labeled for these two emotional states. This
 custom dataset played a crucial role in balancing the distribution of emotions,
 ensuring that the analysis was not biased toward more commonly represented
 emotional states

